{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6235de-7002-4f39-9e7b-2b951825a962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2c32f7d1-e762-44eb-85cf-6724172262eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 694.1535020534246\n",
      "R2_score: 0.9931693788436325\n"
     ]
    }
   ],
   "source": [
    "#  -------------------------------------------\n",
    "###  INPUT ###\n",
    "import pandas as pd\n",
    "input_data = pd.read_csv('2023_smartFarm_AI_hackathon_dataset.csv')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수\n",
    "\n",
    "\n",
    "def preprocessing(input_data):\n",
    "    input_data = input_data.sort_values([\"frmDist\",\"date\"])\n",
    "    input_data[\"date\"] = pd.to_datetime(input_data[\"date\"], format='%Y%m%d')\n",
    "\n",
    "    input_data = input_data.copy()\n",
    "    input_data[\"frmYearWeek\"] = input_data.date.dt.strftime('%Y-%W')\n",
    "    input_data[\"frmYear\"] = input_data.date.dt.strftime('%Y')\n",
    "    input_data[\"frmWeek\"] = input_data.date.dt.strftime('%W').astype(int)\n",
    "    input_data = input_data.sort_values(\"frmYearWeek\")\n",
    "\n",
    "\n",
    "    dd = input_data.groupby(['frmDist', 'frmYearWeek']).agg(\n",
    "        Y=('outtrn_cumsum', 'max'),\n",
    "        Sun_Min=('acSlrdQy', 'min'),\n",
    "        Sun_Max=('acSlrdQy', 'max'),\n",
    "        Sun_Mean=('acSlrdQy', 'mean'),\n",
    "        INTP_Min=('inTp', 'min'),\n",
    "        INTP_Max=('inTp', 'max'),\n",
    "        INTP_Mean=('inTp', 'mean'),\n",
    "        OUTTP_Min=('outTp', 'min'),\n",
    "        OUTTP_Max=('outTp', 'max'),\n",
    "        OUTTP_Mean=('outTp', 'mean'),\n",
    "        minINHD=('inHd', 'min'),\n",
    "        maxINHD=('inHd', 'max'),\n",
    "        meanINHD=('inHd', 'mean'),\n",
    "        minCO2=('inCo2', 'min'),\n",
    "        maxCO2=('inCo2', 'max'),\n",
    "        meanCO2=('inCo2', 'mean'),\n",
    "        minlC=('lefCunt', 'min'),\n",
    "        maxlC=('lefCunt', 'max'),\n",
    "        meanlC=('lefCunt', 'mean'),\n",
    "        minLT=('lefLt', 'min'),\n",
    "        maxLT=('lefLt', 'max'),\n",
    "        meanLT=('lefLt', 'mean'),\n",
    "        minBT=('lefBt', 'min'),\n",
    "        maxBT=('lefBt', 'max'),\n",
    "        meanBT=('lefBt', 'mean'),\n",
    "        meanFrmAr=('frmAr', 'mean'),\n",
    "        meanFRM=('frmDov', 'mean')\n",
    "    ).reset_index()\n",
    "    dd_unique = dd.groupby('frmDist').agg(nn=('frmYearWeek', 'size')).reset_index()\n",
    "    dd_unique_list = dd_unique.query('nn >= 16')\n",
    "\n",
    "    # Filtering based on dd_unique_list\n",
    "    dd = dd[dd['frmDist'].isin(dd_unique_list['frmDist'])]\n",
    "\n",
    "    res = []\n",
    "    for frmDist in dd['frmDist'].unique():\n",
    "        tmp = dd[dd['frmDist'] == frmDist]\n",
    "        arr = tmp['Y'].values\n",
    "        start = (arr != 0).argmax()\n",
    "        real = tmp.iloc[(start - 8) : (start + 8)]\n",
    "\n",
    "        arr = real['Y'].values\n",
    "        for j in range(9, 15):\n",
    "            if arr[j] == 0:\n",
    "                arr[j] = (arr[j - 1] + arr[j + 1]) / 2\n",
    "        Y = arr[-1]\n",
    "        X = real.iloc[14, 3:].values\n",
    "        dataset = pd.DataFrame({'Y': [Y], 'X1': [X[0]], 'X2': [X[1]], 'X3': [X[2]], 'X4': [X[3]], 'X5': [X[4]], 'X6': [X[5]], 'X7': [X[6]],\n",
    "                                'X8': [X[7]], 'X9': [X[8]], 'X10': [X[9]], 'X11': [X[10]], 'X12': [X[11]], 'X13': [X[12]], 'X14': [X[13]],\n",
    "                                'X15': [X[14]],'X16': [X[15]],'X17': [X[16]],'X18': [X[17]], 'X19': [X[18]], 'X20': [X[19]], 'X21': [X[20]],\n",
    "                                'X22': [X[21]],'X23': [X[22]],'X24': [X[23]],'X25': [X[24]],\n",
    "                                'Y1' : [arr[8]], 'Y2' : [arr[9]], 'Y3' : [arr[10]], 'Y4' : [arr[11]], 'Y5' : [arr[12]], 'Y6' : [arr[13]], 'Y7' : [arr[14]]})\n",
    "        res.append(dataset)\n",
    "\n",
    "    result = pd.concat(res, ignore_index=True)\n",
    "\n",
    "    # Filtering based on 'Y' column\n",
    "    result = result[result['Y'] >= 10]\n",
    "\n",
    "    # Scaling columns\n",
    "    #result['Y'] /= result['meanFrmAr']\n",
    "    #result['X1'] /= result['meanFrmAr']\n",
    "    #result['X2'] /= result['meanFrmAr']\n",
    "    #result['X3'] /= result['meanFrmAr']\n",
    "    #result['X4'] /= result['meanFrmAr']\n",
    "    #result['X5'] /= result['meanFrmAr']\n",
    "    #result['X6'] /= result['meanFrmAr']\n",
    "    #result['X7'] /= result['meanFrmAr']\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ... (Data preprocessing code here)\n",
    "# input_data = input_data.drop(columns=['frmDist'])\n",
    "\n",
    "input_data = preprocessing(input_data)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = input_data[input_data.drop(columns=['Y']).columns]\n",
    "Y = input_data[['Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# Initialize and train the LinearRegression model\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=1000, max_depth=5, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict 'y' values using the trained model\n",
    "# X_test= scaler.transform(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate RMSE between the predictions and actual 'y' values\n",
    "def calculate_rmse(targets, predictions):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate r2_score between the predictions and actual 'y' values\n",
    "def calculate_R2_score(y_test,y_pred):\n",
    "    from sklearn.metrics import r2_score\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "rmse = calculate_rmse(y_test, y_pred)\n",
    "r2score = calculate_R2_score(y_test, y_pred)\n",
    "\n",
    "### OUTPUT ###\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2_score:\", r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa288e29-adf3-4220-94ef-11c0e339e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
